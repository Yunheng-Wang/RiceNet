{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T20:40:06.576372Z",
     "end_time": "2023-11-16T20:40:09.272155Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T21:04:23.036357Z",
     "end_time": "2023-11-16T21:04:23.287206Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] 系统找不到指定的路径。: 'D:/Paper reproduction/RiceNet A deep convolutional neural network approach for classification of rice varieties/Dataset/items_train_val_set/train'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[28], line 30\u001B[0m\n\u001B[0;32m     20\u001B[0m \u001B[38;5;66;03m# 配置训练数据集合的数据增强\u001B[39;00m\n\u001B[0;32m     21\u001B[0m train_datagen \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mpreprocessing\u001B[38;5;241m.\u001B[39mimage\u001B[38;5;241m.\u001B[39mImageDataGenerator(\n\u001B[0;32m     22\u001B[0m     rescale\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1.\u001B[39m\u001B[38;5;241m/\u001B[39m\u001B[38;5;241m255\u001B[39m,         \u001B[38;5;66;03m# 图像进行归一化处理\u001B[39;00m\n\u001B[0;32m     23\u001B[0m     rotation_range\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m20\u001B[39m,      \u001B[38;5;66;03m# 旋转角范围 0~20\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     28\u001B[0m     horizontal_flip\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m    \u001B[38;5;66;03m# 是否随机水平翻转\u001B[39;00m\n\u001B[0;32m     29\u001B[0m )\n\u001B[1;32m---> 30\u001B[0m train_generator \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_datagen\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflow_from_directory\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     31\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrain_dir\u001B[49m\u001B[43m,\u001B[49m\u001B[43m                \u001B[49m\u001B[38;5;66;43;03m# train 数据集合 的文件路径\u001B[39;49;00m\n\u001B[0;32m     32\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtarget_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mimage_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m   \u001B[49m\u001B[38;5;66;43;03m# 输出的图像的大小\u001B[39;49;00m\n\u001B[0;32m     33\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# 输出的批次大小\u001B[39;49;00m\n\u001B[0;32m     34\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclass_mode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mcategorical\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;66;03m# 选取分类标签的形式 ， 这里是独热编码 (因为loss是交叉熵损失函数 categorical_crossentropy)\u001B[39;00m\n\u001B[0;32m     37\u001B[0m valid_datagen \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mpreprocessing\u001B[38;5;241m.\u001B[39mimage\u001B[38;5;241m.\u001B[39mImageDataGenerator(rescale\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1.\u001B[39m\u001B[38;5;241m/\u001B[39m\u001B[38;5;241m255\u001B[39m)\n\u001B[0;32m     38\u001B[0m valid_generator \u001B[38;5;241m=\u001B[39m valid_datagen\u001B[38;5;241m.\u001B[39mflow_from_directory(\n\u001B[0;32m     39\u001B[0m         dvi_valid_dir,                \u001B[38;5;66;03m# train 数据集合 的文件路径\u001B[39;00m\n\u001B[0;32m     40\u001B[0m         target_size\u001B[38;5;241m=\u001B[39mimage_size,   \u001B[38;5;66;03m# 输出的图像的大小\u001B[39;00m\n\u001B[0;32m     41\u001B[0m         batch_size\u001B[38;5;241m=\u001B[39mbatch_size,    \u001B[38;5;66;03m# 输出的批次大小\u001B[39;00m\n\u001B[0;32m     42\u001B[0m         class_mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcategorical\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;66;03m# 选取分类标签的形式 ， 这里是独热编码 (因为loss是交叉熵损失函数 categorical_crossentropy)\u001B[39;00m\n",
      "File \u001B[1;32m~\\.anaconda\\envs\\tensorflow\\lib\\site-packages\\keras\\preprocessing\\image.py:976\u001B[0m, in \u001B[0;36mImageDataGenerator.flow_from_directory\u001B[1;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation)\u001B[0m\n\u001B[0;32m    898\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mflow_from_directory\u001B[39m(\u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    899\u001B[0m                         directory,\n\u001B[0;32m    900\u001B[0m                         target_size\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m256\u001B[39m, \u001B[38;5;241m256\u001B[39m),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    911\u001B[0m                         subset\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    912\u001B[0m                         interpolation\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnearest\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[0;32m    913\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Takes the path to a directory & generates batches of augmented data.\u001B[39;00m\n\u001B[0;32m    914\u001B[0m \n\u001B[0;32m    915\u001B[0m \u001B[38;5;124;03m  Args:\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    974\u001B[0m \u001B[38;5;124;03m          and `y` is a numpy array of corresponding labels.\u001B[39;00m\n\u001B[0;32m    975\u001B[0m \u001B[38;5;124;03m  \"\"\"\u001B[39;00m\n\u001B[1;32m--> 976\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mDirectoryIterator\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    977\u001B[0m \u001B[43m      \u001B[49m\u001B[43mdirectory\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    978\u001B[0m \u001B[43m      \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    979\u001B[0m \u001B[43m      \u001B[49m\u001B[43mtarget_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtarget_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    980\u001B[0m \u001B[43m      \u001B[49m\u001B[43mcolor_mode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcolor_mode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    981\u001B[0m \u001B[43m      \u001B[49m\u001B[43mclasses\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mclasses\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    982\u001B[0m \u001B[43m      \u001B[49m\u001B[43mclass_mode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mclass_mode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    983\u001B[0m \u001B[43m      \u001B[49m\u001B[43mdata_format\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata_format\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    984\u001B[0m \u001B[43m      \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    985\u001B[0m \u001B[43m      \u001B[49m\u001B[43mshuffle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mshuffle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    986\u001B[0m \u001B[43m      \u001B[49m\u001B[43mseed\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mseed\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    987\u001B[0m \u001B[43m      \u001B[49m\u001B[43msave_to_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msave_to_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    988\u001B[0m \u001B[43m      \u001B[49m\u001B[43msave_prefix\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msave_prefix\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    989\u001B[0m \u001B[43m      \u001B[49m\u001B[43msave_format\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msave_format\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    990\u001B[0m \u001B[43m      \u001B[49m\u001B[43mfollow_links\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfollow_links\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    991\u001B[0m \u001B[43m      \u001B[49m\u001B[43msubset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msubset\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    992\u001B[0m \u001B[43m      \u001B[49m\u001B[43minterpolation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minterpolation\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.anaconda\\envs\\tensorflow\\lib\\site-packages\\keras\\preprocessing\\image.py:394\u001B[0m, in \u001B[0;36mDirectoryIterator.__init__\u001B[1;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001B[0m\n\u001B[0;32m    392\u001B[0m     dtype \u001B[38;5;241m=\u001B[39m backend\u001B[38;5;241m.\u001B[39mfloatx()\n\u001B[0;32m    393\u001B[0m   kwargs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdtype\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m dtype\n\u001B[1;32m--> 394\u001B[0m \u001B[38;5;28msuper\u001B[39m(DirectoryIterator, \u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(\n\u001B[0;32m    395\u001B[0m     directory, image_data_generator,\n\u001B[0;32m    396\u001B[0m     target_size\u001B[38;5;241m=\u001B[39mtarget_size,\n\u001B[0;32m    397\u001B[0m     color_mode\u001B[38;5;241m=\u001B[39mcolor_mode,\n\u001B[0;32m    398\u001B[0m     classes\u001B[38;5;241m=\u001B[39mclasses,\n\u001B[0;32m    399\u001B[0m     class_mode\u001B[38;5;241m=\u001B[39mclass_mode,\n\u001B[0;32m    400\u001B[0m     batch_size\u001B[38;5;241m=\u001B[39mbatch_size,\n\u001B[0;32m    401\u001B[0m     shuffle\u001B[38;5;241m=\u001B[39mshuffle,\n\u001B[0;32m    402\u001B[0m     seed\u001B[38;5;241m=\u001B[39mseed,\n\u001B[0;32m    403\u001B[0m     data_format\u001B[38;5;241m=\u001B[39mdata_format,\n\u001B[0;32m    404\u001B[0m     save_to_dir\u001B[38;5;241m=\u001B[39msave_to_dir,\n\u001B[0;32m    405\u001B[0m     save_prefix\u001B[38;5;241m=\u001B[39msave_prefix,\n\u001B[0;32m    406\u001B[0m     save_format\u001B[38;5;241m=\u001B[39msave_format,\n\u001B[0;32m    407\u001B[0m     follow_links\u001B[38;5;241m=\u001B[39mfollow_links,\n\u001B[0;32m    408\u001B[0m     subset\u001B[38;5;241m=\u001B[39msubset,\n\u001B[0;32m    409\u001B[0m     interpolation\u001B[38;5;241m=\u001B[39minterpolation,\n\u001B[0;32m    410\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\.anaconda\\envs\\tensorflow\\lib\\site-packages\\keras_preprocessing\\image\\directory_iterator.py:115\u001B[0m, in \u001B[0;36mDirectoryIterator.__init__\u001B[1;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001B[0m\n\u001B[0;32m    113\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m classes:\n\u001B[0;32m    114\u001B[0m     classes \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m--> 115\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m subdir \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28msorted\u001B[39m(\u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlistdir\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdirectory\u001B[49m\u001B[43m)\u001B[49m):\n\u001B[0;32m    116\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39misdir(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(directory, subdir)):\n\u001B[0;32m    117\u001B[0m             classes\u001B[38;5;241m.\u001B[39mappend(subdir)\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [WinError 3] 系统找不到指定的路径。: 'D:/Paper reproduction/RiceNet A deep convolutional neural network approach for classification of rice varieties/Dataset/items_train_val_set/train'"
     ]
    }
   ],
   "source": [
    "\"\"\"加载数据集合\"\"\"\n",
    "# 定义数据集合的文件路径\n",
    "# D 盘\n",
    "train_dir = 'D:/Paper reproduction/RiceNet A deep convolutional neural network approach for classification of rice varieties/Dataset/items_train_val_set/train'\n",
    "valid_dir = 'D:/Paper reproduction/RiceNet A deep convolutional neural network approach for classification of rice varieties/Dataset/items_train_val_set/validation'\n",
    "dvi_valid_dir = 'D:/Paper reproduction/RiceNet A deep convolutional neural network approach for classification of rice varieties/Dataset/items_val_test_set/valid'\n",
    "dvi_test_dir = 'D:/Paper reproduction/RiceNet A deep convolutional neural network approach for classification of rice varieties/Dataset/items_val_test_set/test'\n",
    "\n",
    "'''\n",
    "# C 盘\n",
    "train_dir = 'C:/Users/86155/Desktop/Research/Deep Learning/Image classification application/RiceNet A deep convolutional neural network approach for classification of rice varieties/code_recurrence/Dataset/items_train_val_set/train'\n",
    "valid_dir = 'C:/Users/86155/Desktop/Research/Deep Learning/Image classification application/RiceNet A deep convolutional neural network approach for classification of rice varieties/code_recurrence/Dataset/items_train_val_set/validation'\n",
    "dvi_valid_dir = 'C:/Users/86155/Desktop/Research/Deep Learning/Image classification application/RiceNet A deep convolutional neural network approach for classification of rice varieties/code_recurrence/Dataset/items_val_test_set/valid'\n",
    "dvi_test_dir = 'C:/Users/86155/Desktop/Research/Deep Learning/Image classification application/RiceNet A deep convolutional neural network approach for classification of rice varieties/code_recurrence/Dataset/items_val_test_set/test'\n",
    "'''\n",
    "# 定义批次大小\n",
    "batch_size = 32\n",
    "# 定义图像大小\n",
    "image_size = (512,512)\n",
    "\n",
    "# 配置训练数据集合的数据增强\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255,         # 图像进行归一化处理\n",
    "    rotation_range=20,      # 旋转角范围 0~20\n",
    "    width_shift_range=0.2,  # 水平随机移动范围\n",
    "    height_shift_range=0.2, # 垂直随机移动范围\n",
    "    shear_range=0.2,        # 剪切强度\n",
    "    zoom_range=0.2,         # 随机缩放的范围\n",
    "    horizontal_flip=True    # 是否随机水平翻转\n",
    ")\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,                # train 数据集合 的文件路径\n",
    "        target_size=image_size,   # 输出的图像的大小\n",
    "        batch_size=batch_size,    # 输出的批次大小\n",
    "        class_mode='categorical') # 选取分类标签的形式 ， 这里是独热编码 (因为loss是交叉熵损失函数 categorical_crossentropy)\n",
    "\n",
    "\n",
    "valid_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "valid_generator = valid_datagen.flow_from_directory(\n",
    "        dvi_valid_dir,                # train 数据集合 的文件路径\n",
    "        target_size=image_size,   # 输出的图像的大小\n",
    "        batch_size=batch_size,    # 输出的批次大小\n",
    "        class_mode='categorical') # 选取分类标签的形式 ， 这里是独热编码 (因为loss是交叉熵损失函数 categorical_crossentropy)\n",
    "\n",
    "# 查看标签分配的类别对应的索引\n",
    "train_generator.class_indices , valid_generator.class_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T21:04:36.803226Z",
     "end_time": "2023-11-16T21:04:36.852062Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "共有 5 个类别 , 分别是 ： ['jehlum', 'mushkbudji', 'sr-1', 'sr-2', 'sr-4']\n",
      "训练样本的总数：3430\n",
      "测试集合和验证集合样本的总数：1470\n",
      "验证集合样本的总数：735\n",
      "测试集合样本的总数：735\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\"\"\"找出一共需要多少次批次 tatal_sample = batch_size * num_steps\"\"\"\n",
    "\n",
    "total_class = os.listdir(train_dir)\n",
    "print('共有 {} 个类别 , 分别是 ： {}'.format(len(total_class),total_class))\n",
    "\n",
    "total_train_sample_number = 0\n",
    "for signel_class in total_class:\n",
    "    path = os.path.join(train_dir,signel_class)\n",
    "    total_train_sample_number += len(os.listdir(path))\n",
    "print('训练样本的总数：{}'.format(total_train_sample_number))\n",
    "\n",
    "total_validation_sample_number = 0\n",
    "for signel_class in total_class:\n",
    "    path = os.path.join(valid_dir,signel_class)\n",
    "    total_validation_sample_number += len(os.listdir(path))\n",
    "print('测试集合和验证集合样本的总数：{}'.format(total_validation_sample_number))\n",
    "\n",
    "total_valid_sample_number = 0\n",
    "for signel_class in total_class:\n",
    "    path = os.path.join(dvi_valid_dir,signel_class)\n",
    "    total_valid_sample_number += len(os.listdir(path))\n",
    "print('验证集合样本的总数：{}'.format(total_valid_sample_number))\n",
    "\n",
    "total_test_sample_number = 0\n",
    "for signel_class in total_class:\n",
    "    path = os.path.join(dvi_test_dir,signel_class)\n",
    "    total_test_sample_number += len(os.listdir(path))\n",
    "print('测试集合样本的总数：{}'.format(total_test_sample_number))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T20:03:43.854556Z",
     "end_time": "2023-11-16T20:03:44.688211Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential (Sequential)     (None, 512, 512, 16)      1280      \n",
      "                                                                 \n",
      " sequential_1 (Sequential)   (None, 512, 512, 16)      6480      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 256, 256, 16)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_2 (Sequential)   (None, 256, 256, 32)      4768      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 128, 128, 32)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " sequential_3 (Sequential)   (None, 128, 128, 32)      9376      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 64, 64, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " sequential_4 (Sequential)   (None, 64, 64, 64)        18752     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 32, 32, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " sequential_5 (Sequential)   (None, 32, 32, 64)        37184     \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 16, 16, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " sequential_6 (Sequential)   (None, 16, 16, 128)       74368     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 8, 8, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " sequential_7 (Sequential)   (None, 8, 8, 128)         148096    \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 4, 4, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " sequential_8 (Sequential)   (None, 4, 4, 192)         222144    \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 2, 2, 192)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " sequential_9 (Sequential)   (None, 2, 2, 192)         332736    \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 1, 1, 192)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 192)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 192)               37056     \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 192)              768       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_10 (Activation)  (None, 192)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 192)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5)                 965       \n",
      "                                                                 \n",
      " softmax (Softmax)           (None, 5)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 893,973\n",
      "Trainable params: 891,861\n",
      "Non-trainable params: 2,112\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 定义模型\n",
    "def RiceNet_Block(Conv2D_filters, Conv2D_kernel_size, Conv2D_strides, Conv2D_padding, Activation = 'relu'):\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(filters=Conv2D_filters, kernel_size = Conv2D_kernel_size, strides = Conv2D_strides, padding = Conv2D_padding, use_bias=True),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Activation(Activation)\n",
    "    ])\n",
    "\n",
    "def RiceNet():\n",
    "    RiceNet = tf.keras.Sequential([\n",
    "        # Input layer\n",
    "        tf.keras.layers.InputLayer(input_shape = (512,512,3)),\n",
    "\n",
    "        # big block 1\n",
    "        RiceNet_Block(Conv2D_filters = 16, Conv2D_kernel_size = (5,5), Conv2D_strides = (1,1), Conv2D_padding = 'same', Activation = 'relu'),\n",
    "        # big block 2\n",
    "        RiceNet_Block(Conv2D_filters = 16, Conv2D_kernel_size = (5,5), Conv2D_strides = (1,1), Conv2D_padding = 'same', Activation = 'relu'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2), padding='valid'),\n",
    "        # big block 3\n",
    "        RiceNet_Block(Conv2D_filters = 32, Conv2D_kernel_size = (3,3), Conv2D_strides = (1,1), Conv2D_padding = 'same', Activation = 'relu'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2), padding='valid'),\n",
    "        # big block 4\n",
    "        RiceNet_Block(Conv2D_filters = 32, Conv2D_kernel_size = (3,3), Conv2D_strides = (1,1), Conv2D_padding = 'same', Activation = 'relu'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2), padding='valid'),\n",
    "        # big block 5\n",
    "        RiceNet_Block(Conv2D_filters = 64, Conv2D_kernel_size = (3,3), Conv2D_strides = (1,1), Conv2D_padding = 'same', Activation = 'relu'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2), padding='valid'),\n",
    "        # big block 6\n",
    "        RiceNet_Block(Conv2D_filters = 64, Conv2D_kernel_size = (3,3), Conv2D_strides = (1,1), Conv2D_padding = 'same', Activation = 'relu'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2), padding='valid'),\n",
    "         # big block 7\n",
    "        RiceNet_Block(Conv2D_filters = 128, Conv2D_kernel_size = (3,3), Conv2D_strides = (1,1), Conv2D_padding = 'same', Activation = 'relu'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2), padding='valid'),\n",
    "        # big block 8\n",
    "        RiceNet_Block(Conv2D_filters = 128, Conv2D_kernel_size = (3,3), Conv2D_strides = (1,1), Conv2D_padding = 'same', Activation = 'relu'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2), padding='valid'),\n",
    "        # big block 9\n",
    "        RiceNet_Block(Conv2D_filters = 192, Conv2D_kernel_size = (3,3), Conv2D_strides = (1,1), Conv2D_padding = 'same', Activation = 'relu'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2), padding='valid'),\n",
    "        # big block 10\n",
    "        RiceNet_Block(Conv2D_filters = 192, Conv2D_kernel_size = (3,3), Conv2D_strides = (1,1), Conv2D_padding = 'same', Activation = 'relu'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2), padding='valid'),\n",
    "\n",
    "        # FC layer\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(units = 192),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Activation('relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "\n",
    "        # Output layer\n",
    "        tf.keras.layers.Dense(units = 5),\n",
    "        tf.keras.layers.Softmax()\n",
    "    ])\n",
    "\n",
    "    return RiceNet\n",
    "\n",
    "RiceNet = RiceNet()\n",
    "# 查看模型结构\n",
    "RiceNet.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T19:58:26.370008Z",
     "end_time": "2023-11-16T20:01:25.141406Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "107/107 - 129s - loss: 1.6271 - accuracy: 0.3808 - val_loss: 1.8268 - val_accuracy: 0.2003 - 129s/epoch - 1s/step\n",
      "Epoch 2/50\n",
      "107/107 - 165s - loss: 1.1446 - accuracy: 0.5556 - val_loss: 2.1232 - val_accuracy: 0.2003 - 165s/epoch - 2s/step\n",
      "Epoch 3/50\n",
      "107/107 - 171s - loss: 0.9583 - accuracy: 0.6183 - val_loss: 2.3090 - val_accuracy: 0.2003 - 171s/epoch - 2s/step\n",
      "Epoch 4/50\n",
      "107/107 - 172s - loss: 0.8655 - accuracy: 0.6489 - val_loss: 2.3945 - val_accuracy: 0.1974 - 172s/epoch - 2s/step\n",
      "Epoch 5/50\n",
      "107/107 - 170s - loss: 0.7562 - accuracy: 0.6957 - val_loss: 2.2610 - val_accuracy: 0.3920 - 170s/epoch - 2s/step\n",
      "Epoch 6/50\n",
      "107/107 - 169s - loss: 0.7150 - accuracy: 0.7172 - val_loss: 1.2925 - val_accuracy: 0.6207 - 169s/epoch - 2s/step\n",
      "Epoch 7/50\n",
      "107/107 - 172s - loss: 0.6301 - accuracy: 0.7546 - val_loss: 0.4710 - val_accuracy: 0.8068 - 172s/epoch - 2s/step\n",
      "Epoch 8/50\n",
      "107/107 - 170s - loss: 0.5934 - accuracy: 0.7678 - val_loss: 0.4553 - val_accuracy: 0.8068 - 170s/epoch - 2s/step\n",
      "Epoch 9/50\n",
      "107/107 - 171s - loss: 0.5465 - accuracy: 0.7890 - val_loss: 1.3869 - val_accuracy: 0.6406 - 171s/epoch - 2s/step\n",
      "Epoch 10/50\n",
      "107/107 - 170s - loss: 0.5426 - accuracy: 0.7972 - val_loss: 0.4034 - val_accuracy: 0.8423 - 170s/epoch - 2s/step\n",
      "Epoch 11/50\n",
      "107/107 - 170s - loss: 0.5006 - accuracy: 0.8043 - val_loss: 0.5504 - val_accuracy: 0.8011 - 170s/epoch - 2s/step\n",
      "Epoch 12/50\n",
      "107/107 - 155s - loss: 0.4755 - accuracy: 0.8240 - val_loss: 0.5760 - val_accuracy: 0.7884 - 155s/epoch - 1s/step\n",
      "Epoch 13/50\n",
      "107/107 - 144s - loss: 0.4338 - accuracy: 0.8481 - val_loss: 0.4135 - val_accuracy: 0.8324 - 144s/epoch - 1s/step\n",
      "Epoch 14/50\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 20\u001B[0m\n\u001B[0;32m     18\u001B[0m RiceNet\u001B[38;5;241m.\u001B[39mcompile(optimizer\u001B[38;5;241m=\u001B[39moptimizer,loss\u001B[38;5;241m=\u001B[39mloss,metrics \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maccuracy\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[0;32m     19\u001B[0m \u001B[38;5;66;03m# 训练模型\u001B[39;00m\n\u001B[1;32m---> 20\u001B[0m \u001B[43mRiceNet\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_generator\u001B[49m\u001B[43m,\u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mnum_epochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msteps_per_epoch\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mtotal_train_sample_number\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mvalid_generator\u001B[49m\u001B[43m,\u001B[49m\u001B[43mvalidation_steps\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mtotal_valid_sample_number\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.anaconda\\envs\\tensorflow\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     62\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     63\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 64\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     65\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint: disable=broad-except\u001B[39;00m\n\u001B[0;32m     66\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\.anaconda\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py:1384\u001B[0m, in \u001B[0;36mModel.fit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1377\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[0;32m   1378\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m   1379\u001B[0m     epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[0;32m   1380\u001B[0m     step_num\u001B[38;5;241m=\u001B[39mstep,\n\u001B[0;32m   1381\u001B[0m     batch_size\u001B[38;5;241m=\u001B[39mbatch_size,\n\u001B[0;32m   1382\u001B[0m     _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m):\n\u001B[0;32m   1383\u001B[0m   callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[1;32m-> 1384\u001B[0m   tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1385\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[0;32m   1386\u001B[0m     context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[1;32m~\\.anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\.anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    912\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    914\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[1;32m--> 915\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m    917\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[0;32m    918\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[1;32m~\\.anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001B[0m, in \u001B[0;36mFunction._call\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    944\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[0;32m    945\u001B[0m   \u001B[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001B[39;00m\n\u001B[0;32m    946\u001B[0m   \u001B[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001B[39;00m\n\u001B[1;32m--> 947\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stateless_fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)  \u001B[38;5;66;03m# pylint: disable=not-callable\u001B[39;00m\n\u001B[0;32m    948\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stateful_fn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    949\u001B[0m   \u001B[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001B[39;00m\n\u001B[0;32m    950\u001B[0m   \u001B[38;5;66;03m# in parallel.\u001B[39;00m\n\u001B[0;32m    951\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n",
      "File \u001B[1;32m~\\.anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2956\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   2953\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[0;32m   2954\u001B[0m   (graph_function,\n\u001B[0;32m   2955\u001B[0m    filtered_flat_args) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_define_function(args, kwargs)\n\u001B[1;32m-> 2956\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mgraph_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   2957\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfiltered_flat_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgraph_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1853\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[1;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[0;32m   1849\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[0;32m   1850\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[0;32m   1851\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[0;32m   1852\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[1;32m-> 1853\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_call_outputs(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1854\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcancellation_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcancellation_manager\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m   1855\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[0;32m   1856\u001B[0m     args,\n\u001B[0;32m   1857\u001B[0m     possible_gradient_type,\n\u001B[0;32m   1858\u001B[0m     executing_eagerly)\n\u001B[0;32m   1859\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[1;32m~\\.anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001B[0m, in \u001B[0;36m_EagerDefinedFunction.call\u001B[1;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[0;32m    497\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _InterpolateFunctionError(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    498\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m cancellation_manager \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 499\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    500\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msignature\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    501\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_num_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    502\u001B[0m \u001B[43m        \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    503\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    504\u001B[0m \u001B[43m        \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mctx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    505\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    506\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[0;32m    507\u001B[0m         \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msignature\u001B[38;5;241m.\u001B[39mname),\n\u001B[0;32m    508\u001B[0m         num_outputs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_outputs,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    511\u001B[0m         ctx\u001B[38;5;241m=\u001B[39mctx,\n\u001B[0;32m    512\u001B[0m         cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_manager)\n",
      "File \u001B[1;32m~\\.anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001B[0m, in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     53\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[1;32m---> 54\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     55\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     56\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     57\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# 训练\n",
    "from PIL import Image, ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "'''\n",
    "checkpoint_path = \"training_8/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,monitor='val_acc', save_best_only=True, mode='auto',\n",
    "                                                 verbose=1)\n",
    "'''\n",
    "lr = 0.00003\n",
    "num_epochs = 50\n",
    "# 直接返回 steps 的方法\n",
    "# total_train_samples = len(train_generator.filenames)\n",
    "# total_validation_samples = len(test_generator.filenames)\n",
    "# 配置模型\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate = lr)\n",
    "RiceNet.compile(optimizer=optimizer,loss=loss,metrics = ['accuracy'])\n",
    "# 训练模型\n",
    "RiceNet.fit(train_generator,epochs = num_epochs, verbose = 2, steps_per_epoch = total_train_sample_number // batch_size, validation_data = valid_generator,validation_steps = total_valid_sample_number // batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-16T21:06:51.278409Z",
     "end_time": "2023-11-16T21:12:38.206654Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107/107 - 156s - loss: 1.1471 - accuracy: 0.5447 - val_loss: 1.3294 - val_accuracy: 0.6847 - 156s/epoch - 1s/step\n",
      "107/107 - 186s - loss: 0.5111 - accuracy: 0.8011 - val_loss: 0.4217 - val_accuracy: 0.9304 - 186s/epoch - 2s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x1e3df5fe880>"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transfer model of  InceptionV3\n",
    "\n",
    "# load pre-training model\n",
    "\n",
    "pre_training_InceptionV3 = tf.keras.applications.InceptionV3(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_shape=(512, 512, 3),\n",
    "    pooling=None,\n",
    ")\n",
    "lr = 0.00003\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate = lr)\n",
    "\n",
    "# The first steps\n",
    "\n",
    "# 参数冻结\n",
    "pre_training_InceptionV3.trainable = False\n",
    "layer_229_output = pre_training_InceptionV3.output\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(layer_229_output)\n",
    "x = tf.keras.layers.Dense(units = 1024)(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Activation('relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "x = tf.keras.layers.Dense(units = 5)(x)\n",
    "x = tf.keras.layers.Softmax()(x)\n",
    "\n",
    "from PIL import Image, ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "first_step_InceptionV3 = tf.keras.Model(inputs = pre_training_InceptionV3.input, outputs = x)\n",
    "\n",
    "first_step_InceptionV3.compile(optimizer=optimizer,loss=loss,metrics = ['accuracy'])\n",
    "first_step_InceptionV3.fit(train_generator,epochs = 30, verbose = 2, steps_per_epoch = total_train_sample_number // batch_size, validation_data = valid_generator,validation_steps = total_valid_sample_number // batch_size)\n",
    "\n",
    "\n",
    "# The second steps\n",
    "idx_mixed7 = 0\n",
    "for i,layer in enumerate(pre_training_InceptionV3.layers):\n",
    "    if layer.name == 'mixed7':\n",
    "        idx_mixed7 = i\n",
    "\n",
    "for layer in first_step_InceptionV3.layers[idx_mixed7+1:]:\n",
    "     layer.trainable = True\n",
    "\n",
    "InceptionV3 =  tf.keras.Model(inputs = first_step_InceptionV3.input, outputs = first_step_InceptionV3.output)\n",
    "InceptionV3.compile(optimizer=optimizer,loss=loss,metrics = ['accuracy'])\n",
    "InceptionV3.fit(train_generator,epochs = 30, verbose = 2, steps_per_epoch = total_train_sample_number // batch_size, validation_data = valid_generator,validation_steps = total_valid_sample_number // batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_resnet_v2/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "   221184/219055592 [..............................] - ETA: 28:14"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[27], line 4\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# transfer model of InceptionResNetV2\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \n\u001B[0;32m      3\u001B[0m \u001B[38;5;66;03m# load pre-training model\u001B[39;00m\n\u001B[1;32m----> 4\u001B[0m pre_training_InceptionResNetV2 \u001B[38;5;241m=\u001B[39m \u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkeras\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapplications\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minception_resnet_v2\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mInceptionResNetV2\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[43minclude_top\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[43m    \u001B[49m\u001B[43mweights\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mimagenet\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_shape\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m512\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;241;43m512\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      8\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpooling\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m      9\u001B[0m \u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.anaconda\\envs\\tensorflow\\lib\\site-packages\\keras\\applications\\inception_resnet_v2.py:243\u001B[0m, in \u001B[0;36mInceptionResNetV2\u001B[1;34m(include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation, **kwargs)\u001B[0m\n\u001B[0;32m    240\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    241\u001B[0m     fname \u001B[38;5;241m=\u001B[39m (\u001B[38;5;124m'\u001B[39m\u001B[38;5;124minception_resnet_v2_weights_\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    242\u001B[0m              \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtf_dim_ordering_tf_kernels_notop.h5\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m--> 243\u001B[0m     weights_path \u001B[38;5;241m=\u001B[39m \u001B[43mdata_utils\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_file\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    244\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    245\u001B[0m \u001B[43m        \u001B[49m\u001B[43mBASE_WEIGHT_URL\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mfname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    246\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcache_subdir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmodels\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    247\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfile_hash\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43md19885ff4a710c122648d3b5c3b684e4\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    248\u001B[0m   model\u001B[38;5;241m.\u001B[39mload_weights(weights_path)\n\u001B[0;32m    249\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m weights \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32m~\\.anaconda\\envs\\tensorflow\\lib\\site-packages\\keras\\utils\\data_utils.py:277\u001B[0m, in \u001B[0;36mget_file\u001B[1;34m(fname, origin, untar, md5_hash, file_hash, cache_subdir, hash_algorithm, extract, archive_format, cache_dir)\u001B[0m\n\u001B[0;32m    275\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    276\u001B[0m   \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 277\u001B[0m     \u001B[43murlretrieve\u001B[49m\u001B[43m(\u001B[49m\u001B[43morigin\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfpath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdl_progress\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    278\u001B[0m   \u001B[38;5;28;01mexcept\u001B[39;00m urllib\u001B[38;5;241m.\u001B[39merror\u001B[38;5;241m.\u001B[39mHTTPError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    279\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m(error_msg\u001B[38;5;241m.\u001B[39mformat(origin, e\u001B[38;5;241m.\u001B[39mcode, e\u001B[38;5;241m.\u001B[39mmsg))\n",
      "File \u001B[1;32m~\\.anaconda\\envs\\tensorflow\\lib\\site-packages\\keras\\utils\\data_utils.py:84\u001B[0m, in \u001B[0;36murlretrieve\u001B[1;34m(url, filename, reporthook, data)\u001B[0m\n\u001B[0;32m     82\u001B[0m response \u001B[38;5;241m=\u001B[39m urlopen(url, data)\n\u001B[0;32m     83\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(filename, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mwb\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m fd:\n\u001B[1;32m---> 84\u001B[0m   \u001B[38;5;28;01mfor\u001B[39;00m chunk \u001B[38;5;129;01min\u001B[39;00m chunk_read(response, reporthook\u001B[38;5;241m=\u001B[39mreporthook):\n\u001B[0;32m     85\u001B[0m     fd\u001B[38;5;241m.\u001B[39mwrite(chunk)\n",
      "File \u001B[1;32m~\\.anaconda\\envs\\tensorflow\\lib\\site-packages\\keras\\utils\\data_utils.py:73\u001B[0m, in \u001B[0;36murlretrieve.<locals>.chunk_read\u001B[1;34m(response, chunk_size, reporthook)\u001B[0m\n\u001B[0;32m     71\u001B[0m count \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m     72\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m---> 73\u001B[0m   chunk \u001B[38;5;241m=\u001B[39m \u001B[43mresponse\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mchunk_size\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     74\u001B[0m   count \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m     75\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m reporthook \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32m~\\.anaconda\\envs\\tensorflow\\lib\\http\\client.py:463\u001B[0m, in \u001B[0;36mHTTPResponse.read\u001B[1;34m(self, amt)\u001B[0m\n\u001B[0;32m    460\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m amt \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    461\u001B[0m     \u001B[38;5;66;03m# Amount is given, implement using readinto\u001B[39;00m\n\u001B[0;32m    462\u001B[0m     b \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mbytearray\u001B[39m(amt)\n\u001B[1;32m--> 463\u001B[0m     n \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreadinto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    464\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mmemoryview\u001B[39m(b)[:n]\u001B[38;5;241m.\u001B[39mtobytes()\n\u001B[0;32m    465\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    466\u001B[0m     \u001B[38;5;66;03m# Amount is not given (unbounded read) so we must check self.length\u001B[39;00m\n\u001B[0;32m    467\u001B[0m     \u001B[38;5;66;03m# and self.chunked\u001B[39;00m\n",
      "File \u001B[1;32m~\\.anaconda\\envs\\tensorflow\\lib\\http\\client.py:507\u001B[0m, in \u001B[0;36mHTTPResponse.readinto\u001B[1;34m(self, b)\u001B[0m\n\u001B[0;32m    502\u001B[0m         b \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mmemoryview\u001B[39m(b)[\u001B[38;5;241m0\u001B[39m:\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlength]\n\u001B[0;32m    504\u001B[0m \u001B[38;5;66;03m# we do not use _safe_read() here because this may be a .will_close\u001B[39;00m\n\u001B[0;32m    505\u001B[0m \u001B[38;5;66;03m# connection, and the user is reading more bytes than will be provided\u001B[39;00m\n\u001B[0;32m    506\u001B[0m \u001B[38;5;66;03m# (for example, reading in 1k chunks)\u001B[39;00m\n\u001B[1;32m--> 507\u001B[0m n \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreadinto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    508\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m n \u001B[38;5;129;01mand\u001B[39;00m b:\n\u001B[0;32m    509\u001B[0m     \u001B[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001B[39;00m\n\u001B[0;32m    510\u001B[0m     \u001B[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001B[39;00m\n\u001B[0;32m    511\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_close_conn()\n",
      "File \u001B[1;32m~\\.anaconda\\envs\\tensorflow\\lib\\socket.py:704\u001B[0m, in \u001B[0;36mSocketIO.readinto\u001B[1;34m(self, b)\u001B[0m\n\u001B[0;32m    702\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m    703\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 704\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrecv_into\u001B[49m\u001B[43m(\u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    705\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m timeout:\n\u001B[0;32m    706\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_timeout_occurred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[1;32m~\\.anaconda\\envs\\tensorflow\\lib\\ssl.py:1242\u001B[0m, in \u001B[0;36mSSLSocket.recv_into\u001B[1;34m(self, buffer, nbytes, flags)\u001B[0m\n\u001B[0;32m   1238\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m flags \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m   1239\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   1240\u001B[0m           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m\n\u001B[0;32m   1241\u001B[0m           \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m)\n\u001B[1;32m-> 1242\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnbytes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbuffer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1243\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1244\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001B[1;32m~\\.anaconda\\envs\\tensorflow\\lib\\ssl.py:1100\u001B[0m, in \u001B[0;36mSSLSocket.read\u001B[1;34m(self, len, buffer)\u001B[0m\n\u001B[0;32m   1098\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1099\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m buffer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 1100\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sslobj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbuffer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1101\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1102\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sslobj\u001B[38;5;241m.\u001B[39mread(\u001B[38;5;28mlen\u001B[39m)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# transfer model of InceptionResNetV2\n",
    "\n",
    "# load pre-training model\n",
    "pre_training_InceptionResNetV2 = tf.keras.applications.inception_resnet_v2.InceptionResNetV2(\n",
    "    include_top = False,\n",
    "    weights = 'imagenet',\n",
    "    input_shape = (512,512,3),\n",
    "    pooling = None,\n",
    ")\n",
    "\n",
    "lr = 0.00003\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate = lr)\n",
    "\n",
    "# The first steps\n",
    "pre_training_InceptionResNetV2.trainable = False\n",
    "layer_InceptionResNetV2_output = pre_training_InceptionResNetV2.output\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(layer_InceptionResNetV2_output)\n",
    "X = tf.keras.layers.Dense(units = 512)(x)\n",
    "x = tf.keras.layers.Dropout(0.3)(x)\n",
    "x = tf.keras.layers.Activation('relu')(x)\n",
    "X = tf.keras.layers.Dense(units = 128)(x)\n",
    "x = tf.keras.layers.Dropout(0.3)(x)\n",
    "x = tf.keras.layers.Activation('relu')(x)\n",
    "x = tf.keras.layers.Dense(units = 5)(x)\n",
    "x = tf.keras.layers.Softmax()(x)\n",
    "first_step_InceptionResNetV2 = tf.keras.Model(inputs = pre_training_InceptionResNetV2.input, outputs = x)\n",
    "\n",
    "from PIL import Image, ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "first_step_InceptionResNetV2.compile(optimizer=optimizer,loss=loss,metrics = ['accuracy'])\n",
    "first_step_InceptionResNetV2.fit(train_generator,epochs = 30, verbose = 2, steps_per_epoch = total_train_sample_number // batch_size, validation_data = valid_generator,validation_steps = total_valid_sample_number // batch_size)\n",
    "\n",
    "# The second steps\n",
    "first_step_InceptionResNetV2.trainable = True\n",
    "InceptionResNetV2 = tf.keras.Model(inputs = first_step_InceptionResNetV2.input, outputs = first_step_InceptionResNetV2.output)\n",
    "\n",
    "InceptionResNetV2.compile(optimizer=optimizer,loss=loss,metrics = ['accuracy'])\n",
    "InceptionResNetV2.fit(train_generator,epochs = 30, verbose = 2, steps_per_epoch = total_train_sample_number // batch_size, validation_data = valid_generator,validation_steps = total_valid_sample_number // batch_size)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
