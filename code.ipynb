{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-11-15T15:54:45.139708Z",
     "end_time": "2023-11-15T15:54:53.270553Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3430 images belonging to 5 classes.\n",
      "Found 735 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": "({'jehlum': 0, 'mushkbudji': 1, 'sr-1': 2, 'sr-2': 3, 'sr-4': 4},\n {'jehlum': 0, 'mushkbudji': 1, 'sr-1': 2, 'sr-2': 3, 'sr-4': 4})"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"加载数据集合\"\"\"\n",
    "# 定义训练数据的文件路径\n",
    "train_dir = 'D:/Paper reproduction/RiceNet A deep convolutional neural network approach for classification of rice varieties/Dataset/items_train_val_set/train'\n",
    "valid_dir = 'D:/Paper reproduction/RiceNet A deep convolutional neural network approach for classification of rice varieties/Dataset/items_train_val_set/validation'\n",
    "dvi_valid_dir = 'D:/Paper reproduction/RiceNet A deep convolutional neural network approach for classification of rice varieties/Dataset/items_val_test_set/valid'\n",
    "# 定义批次大小\n",
    "batch_size = 32\n",
    "# 定义图像大小\n",
    "image_size = (512,512)\n",
    "\n",
    "# 配置训练数据集合的数据增强\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255,         # 图像进行归一化处理\n",
    "    rotation_range=20,      # 旋转角范围 0~20\n",
    "    width_shift_range=0.2,  # 水平随机移动范围\n",
    "    height_shift_range=0.2, # 垂直随机移动范围\n",
    "    shear_range=0.2,        # 剪切强度\n",
    "    zoom_range=0.2,         # 随机缩放的范围\n",
    "    horizontal_flip=True    # 是否随机水平翻转\n",
    ")\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,                # train 数据集合 的文件路径\n",
    "        target_size=image_size,   # 输出的图像的大小\n",
    "        batch_size=batch_size,    # 输出的批次大小\n",
    "        class_mode='categorical') # 选取分类标签的形式 ， 这里是独热编码 (因为loss是交叉熵损失函数 categorical_crossentropy)\n",
    "\n",
    "# 配置测试数据集合的数据增强\n",
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        dvi_valid_dir,                # train 数据集合 的文件路径\n",
    "        target_size=image_size,   # 输出的图像的大小\n",
    "        batch_size=batch_size,    # 输出的批次大小\n",
    "        class_mode='categorical') # 选取分类标签的形式 ， 这里是独热编码 (因为loss是交叉熵损失函数 categorical_crossentropy)\n",
    "\n",
    "# 查看标签分配的类别对应的索引\n",
    "train_generator.class_indices , test_generator.class_indices\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-15T15:55:56.015433Z",
     "end_time": "2023-11-15T15:55:56.193504Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "共有 5 个类别 , 分别是 ： ['jehlum', 'mushkbudji', 'sr-1', 'sr-2', 'sr-4']\n",
      "训练样本的总数：3430\n",
      "测试集合和验证集合样本的总数：1470\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\"\"\"找出一共需要多少次批次 tatal_sample = batch_size * num_steps\"\"\"\n",
    "\n",
    "total_class = os.listdir(train_dir)\n",
    "print('共有 {} 个类别 , 分别是 ： {}'.format(len(total_class),total_class))\n",
    "\n",
    "total_train_sample_number = 0\n",
    "for signel_class in total_class:\n",
    "    path = os.path.join(train_dir,signel_class)\n",
    "    total_train_sample_number += len(os.listdir(path))\n",
    "print('训练样本的总数：{}'.format(total_train_sample_number))\n",
    "\n",
    "total_validation_sample_number = 0\n",
    "for signel_class in total_class:\n",
    "    path = os.path.join(valid_dir,signel_class)\n",
    "    total_validation_sample_number += len(os.listdir(path))\n",
    "print('测试集合和验证集合样本的总数：{}'.format(total_validation_sample_number))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-13T22:24:41.318408Z",
     "end_time": "2023-11-13T22:24:41.378447Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential (Sequential)     (None, 512, 512, 16)      1280      \n",
      "                                                                 \n",
      " sequential_1 (Sequential)   (None, 512, 512, 16)      6480      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 256, 256, 16)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " sequential_2 (Sequential)   (None, 256, 256, 32)      4768      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 128, 128, 32)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " sequential_3 (Sequential)   (None, 128, 128, 32)      9376      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 64, 64, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " sequential_4 (Sequential)   (None, 64, 64, 64)        18752     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 32, 32, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " sequential_5 (Sequential)   (None, 32, 32, 64)        37184     \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 16, 16, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " sequential_6 (Sequential)   (None, 16, 16, 128)       74368     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 8, 8, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " sequential_7 (Sequential)   (None, 8, 8, 128)         148096    \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 4, 4, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " sequential_8 (Sequential)   (None, 4, 4, 192)         222144    \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 2, 2, 192)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " sequential_9 (Sequential)   (None, 2, 2, 192)         332736    \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 1, 1, 192)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 192)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 192)               37056     \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 192)              768       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_10 (Activation)  (None, 192)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 192)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5)                 965       \n",
      "                                                                 \n",
      " softmax (Softmax)           (None, 5)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 893,973\n",
      "Trainable params: 891,861\n",
      "Non-trainable params: 2,112\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 定义模型\n",
    "def RiceNet_Block(Conv2D_filters, Conv2D_kernel_size, Conv2D_strides, Conv2D_padding, Activation = 'relu'):\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(filters=Conv2D_filters, kernel_size = Conv2D_kernel_size, strides = Conv2D_strides, padding = Conv2D_padding, use_bias=True),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Activation(Activation)\n",
    "    ])\n",
    "\n",
    "def RiceNet():\n",
    "    RiceNet = tf.keras.Sequential([\n",
    "        # Input layer\n",
    "        tf.keras.layers.InputLayer(input_shape = (512,512,3)),\n",
    "\n",
    "        # big block 1\n",
    "        RiceNet_Block(Conv2D_filters = 16, Conv2D_kernel_size = (5,5), Conv2D_strides = (1,1), Conv2D_padding = 'same', Activation = 'relu'),\n",
    "        # big block 2\n",
    "        RiceNet_Block(Conv2D_filters = 16, Conv2D_kernel_size = (5,5), Conv2D_strides = (1,1), Conv2D_padding = 'same', Activation = 'relu'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2), padding='valid'),\n",
    "        # big block 3\n",
    "        RiceNet_Block(Conv2D_filters = 32, Conv2D_kernel_size = (3,3), Conv2D_strides = (1,1), Conv2D_padding = 'same', Activation = 'relu'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2), padding='valid'),\n",
    "        # big block 4\n",
    "        RiceNet_Block(Conv2D_filters = 32, Conv2D_kernel_size = (3,3), Conv2D_strides = (1,1), Conv2D_padding = 'same', Activation = 'relu'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2), padding='valid'),\n",
    "        # big block 5\n",
    "        RiceNet_Block(Conv2D_filters = 64, Conv2D_kernel_size = (3,3), Conv2D_strides = (1,1), Conv2D_padding = 'same', Activation = 'relu'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2), padding='valid'),\n",
    "        # big block 6\n",
    "        RiceNet_Block(Conv2D_filters = 64, Conv2D_kernel_size = (3,3), Conv2D_strides = (1,1), Conv2D_padding = 'same', Activation = 'relu'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2), padding='valid'),\n",
    "         # big block 7\n",
    "        RiceNet_Block(Conv2D_filters = 128, Conv2D_kernel_size = (3,3), Conv2D_strides = (1,1), Conv2D_padding = 'same', Activation = 'relu'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2), padding='valid'),\n",
    "        # big block 8\n",
    "        RiceNet_Block(Conv2D_filters = 128, Conv2D_kernel_size = (3,3), Conv2D_strides = (1,1), Conv2D_padding = 'same', Activation = 'relu'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2), padding='valid'),\n",
    "        # big block 9\n",
    "        RiceNet_Block(Conv2D_filters = 192, Conv2D_kernel_size = (3,3), Conv2D_strides = (1,1), Conv2D_padding = 'same', Activation = 'relu'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2), padding='valid'),\n",
    "        # big block 10\n",
    "        RiceNet_Block(Conv2D_filters = 192, Conv2D_kernel_size = (3,3), Conv2D_strides = (1,1), Conv2D_padding = 'same', Activation = 'relu'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2), padding='valid'),\n",
    "\n",
    "        # FC layer\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(units = 192),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Activation('relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "\n",
    "        # Output layer\n",
    "        tf.keras.layers.Dense(units = 5),\n",
    "        tf.keras.layers.Softmax()\n",
    "    ])\n",
    "\n",
    "    return RiceNet\n",
    "\n",
    "RiceNet = RiceNet()\n",
    "# 查看模型结构\n",
    "RiceNet.summary()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-13T22:24:41.342331Z",
     "end_time": "2023-11-13T22:24:42.401983Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "unrecognized data stream contents when reading image file",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mOSError\u001B[0m                                   Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[5], line 9\u001B[0m\n\u001B[0;32m      7\u001B[0m RiceNet\u001B[38;5;241m.\u001B[39mcompile(optimizer\u001B[38;5;241m=\u001B[39moptimizer,loss\u001B[38;5;241m=\u001B[39mloss,metrics \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maccuracy\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[0;32m      8\u001B[0m \u001B[38;5;66;03m# 训练模型\u001B[39;00m\n\u001B[1;32m----> 9\u001B[0m \u001B[43mRiceNet\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_generator\u001B[49m\u001B[43m,\u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mnum_epochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msteps_per_epoch\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mtotal_train_sample_number\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m4\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_steps\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mtotal_validation_sample_number\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m4\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.anaconda\\envs\\tensorflow\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     65\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint: disable=broad-except\u001B[39;00m\n\u001B[0;32m     66\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m---> 67\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     68\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     69\u001B[0m   \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32m~\\.anaconda\\envs\\tensorflow\\lib\\site-packages\\PIL\\Image.py:2138\u001B[0m, in \u001B[0;36mImage.resize\u001B[1;34m(self, size, resample, box, reducing_gap)\u001B[0m\n\u001B[0;32m   2134\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(msg)\n\u001B[0;32m   2136\u001B[0m size \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mtuple\u001B[39m(size)\n\u001B[1;32m-> 2138\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2139\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m box \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   2140\u001B[0m     box \u001B[38;5;241m=\u001B[39m (\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m0\u001B[39m) \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msize\n",
      "File \u001B[1;32m~\\.anaconda\\envs\\tensorflow\\lib\\site-packages\\PIL\\ImageFile.py:288\u001B[0m, in \u001B[0;36mImageFile.load\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    284\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    286\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmap \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m LOAD_TRUNCATED_IMAGES \u001B[38;5;129;01mand\u001B[39;00m err_code \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m    287\u001B[0m     \u001B[38;5;66;03m# still raised if decoder fails to return anything\u001B[39;00m\n\u001B[1;32m--> 288\u001B[0m     \u001B[43mraise_oserror\u001B[49m\u001B[43m(\u001B[49m\u001B[43merr_code\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    290\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m Image\u001B[38;5;241m.\u001B[39mImage\u001B[38;5;241m.\u001B[39mload(\u001B[38;5;28mself\u001B[39m)\n",
      "File \u001B[1;32m~\\.anaconda\\envs\\tensorflow\\lib\\site-packages\\PIL\\ImageFile.py:72\u001B[0m, in \u001B[0;36mraise_oserror\u001B[1;34m(error)\u001B[0m\n\u001B[0;32m     70\u001B[0m     msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdecoder error \u001B[39m\u001B[38;5;132;01m{\u001B[39;00merror\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     71\u001B[0m msg \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m when reading image file\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m---> 72\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m(msg)\n",
      "\u001B[1;31mOSError\u001B[0m: unrecognized data stream contents when reading image file"
     ]
    }
   ],
   "source": [
    "# 训练\n",
    "lr = 0.00003\n",
    "num_epochs = 50\n",
    "# 配置模型\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate = lr)\n",
    "RiceNet.compile(optimizer=optimizer,loss=loss,metrics = ['accuracy'])\n",
    "# 训练模型\n",
    "RiceNet.fit(train_generator,epochs = num_epochs, verbose = 2, steps_per_epoch = total_train_sample_number // batch_size, validation_steps = total_validation_sample_number // batch_size, batch_size = batch_size)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-13T20:28:57.257181Z",
     "end_time": "2023-11-13T20:28:57.267464Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "When setting `include_top=True` and loading `imagenet` weights, `input_shape` should be (299, 299, 3).  Received: input_shape=(512, 512, 3)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 4\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# transfer model of  InceptionV3\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \n\u001B[0;32m      3\u001B[0m \u001B[38;5;66;03m# load pre-training model\u001B[39;00m\n\u001B[1;32m----> 4\u001B[0m pre_training_InceptionV3 \u001B[38;5;241m=\u001B[39m \u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkeras\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapplications\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minception_v3\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mInceptionV3\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[43minclude_top\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[43m    \u001B[49m\u001B[43mweights\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mimagenet\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_shape\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m512\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;241;43m512\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      8\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpooling\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m      9\u001B[0m \u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.anaconda\\envs\\tensorflow\\lib\\site-packages\\keras\\applications\\inception_v3.py:127\u001B[0m, in \u001B[0;36mInceptionV3\u001B[1;34m(include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation)\u001B[0m\n\u001B[0;32m    122\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mIf using `weights` as `\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mimagenet\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m` with `include_top` \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    123\u001B[0m                    \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mas true, `classes` should be 1000; \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    124\u001B[0m                    \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mReceived classes=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mclasses\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m    126\u001B[0m \u001B[38;5;66;03m# Determine proper input shape\u001B[39;00m\n\u001B[1;32m--> 127\u001B[0m input_shape \u001B[38;5;241m=\u001B[39m \u001B[43mimagenet_utils\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mobtain_input_shape\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    128\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_shape\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    129\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdefault_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m299\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    130\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmin_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m75\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    131\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdata_format\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbackend\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimage_data_format\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    132\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrequire_flatten\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minclude_top\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    133\u001B[0m \u001B[43m    \u001B[49m\u001B[43mweights\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mweights\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    135\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m input_tensor \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    136\u001B[0m   img_input \u001B[38;5;241m=\u001B[39m layers\u001B[38;5;241m.\u001B[39mInput(shape\u001B[38;5;241m=\u001B[39minput_shape)\n",
      "File \u001B[1;32m~\\.anaconda\\envs\\tensorflow\\lib\\site-packages\\keras\\applications\\imagenet_utils.py:349\u001B[0m, in \u001B[0;36mobtain_input_shape\u001B[1;34m(input_shape, default_size, min_size, data_format, require_flatten, weights)\u001B[0m\n\u001B[0;32m    347\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m input_shape \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    348\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m input_shape \u001B[38;5;241m!=\u001B[39m default_shape:\n\u001B[1;32m--> 349\u001B[0m       \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mWhen setting `include_top=True` \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    350\u001B[0m                        \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mand loading `imagenet` weights, \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    351\u001B[0m                        \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m`input_shape` should be \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdefault_shape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.  \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    352\u001B[0m                        \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mReceived: input_shape=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00minput_shape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m    353\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m default_shape\n\u001B[0;32m    354\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m input_shape:\n",
      "\u001B[1;31mValueError\u001B[0m: When setting `include_top=True` and loading `imagenet` weights, `input_shape` should be (299, 299, 3).  Received: input_shape=(512, 512, 3)"
     ]
    }
   ],
   "source": [
    "# transfer model of  InceptionV3\n",
    "\n",
    "# load pre-training model\n",
    "pre_training_InceptionV3 = tf.keras.applications.inception_v3.InceptionV3(\n",
    "    include_top = False,\n",
    "    weights = 'imagenet',\n",
    "    input_shape = (512,512,3),\n",
    "    pooling = None,\n",
    ")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-14T23:58:44.115812Z",
     "end_time": "2023-11-14T23:58:45.957499Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# transfer model of InceptionResNetV2\n",
    "\n",
    "# load pre-training model\n",
    "pre_training_InceptionResNetV2 = tf.keras.applications.inception_resnet_v2.InceptionResNetV2(\n",
    "    include_top = False,\n",
    "    weights = 'imagenet',\n",
    "    input_shape = (512,512,3),\n",
    "    pooling = None,\n",
    ")\n",
    "#"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
